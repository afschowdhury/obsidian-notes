{
  "main": {
    "id": "801ee49c2d006a5f",
    "type": "split",
    "children": [
      {
        "id": "042a5d16a8aa0bdf",
        "type": "tabs",
        "children": [
          {
            "id": "8ebee336ddc36709",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/Advantage of using Langchain.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "6292c966fc7c5509",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/Memory in Langchain.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "e908fb48cde538ee",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/ConversationSummaryMemory.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "3f58fcf0ebeb754b",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/ConversationTokenBufferMemory.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "22cd85e9a9deb758",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/ConversationBufferWindowMemory.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "107da68dff453a6e",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/ConversationBufferMemory.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "e59ca0445b94c53c",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/Why we need output parser.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "cc144790cd89da6a",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/What is output parser.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "c47a3f6af54a27be",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/LLM Notes.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "739a8be242298bac",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/Memory in Langchain.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "9451b9fc40c2d829",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/Advantage of ChatPromptTemplate over PromptTemplate on chat models.md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "d3d03f7bf6f49838",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "LLM/LLM Notes.md",
                "mode": "source",
                "source": false
              }
            }
          }
        ],
        "currentTab": 11
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "79793af05ec478d3",
    "type": "split",
    "children": [
      {
        "id": "98fc356f7eff151a",
        "type": "tabs",
        "children": [
          {
            "id": "a8e933d0dee0e344",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical"
              }
            }
          },
          {
            "id": "a30662451c3b4de4",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              }
            }
          },
          {
            "id": "f1d136e0d0c349bc",
            "type": "leaf",
            "state": {
              "type": "starred",
              "state": {}
            }
          },
          {
            "id": "4b51da36e3ab7666",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {}
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 245.5
  },
  "right": {
    "id": "30a6f45e97eb79e9",
    "type": "split",
    "children": [
      {
        "id": "62cbab635d1b4995",
        "type": "tabs",
        "children": [
          {
            "id": "404cea0c96dc994c",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "LLM/LLM Notes.md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "eec63b112a83a6d6",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "LLM/LLM Notes.md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "fb3007d8efa074b0",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              }
            }
          },
          {
            "id": "cbaa088ba032ecce",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "LLM/LLM Notes.md"
              }
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 200,
    "collapsed": true
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false,
      "templater-obsidian:Templater": false,
      "obsidian-excalidraw-plugin:Create new drawing": false,
      "obsidian-to-notion:Share to notion": false,
      "obsidian-raindrop-highlights:Sync your Raindrop highlights": false
    }
  },
  "active": "d3d03f7bf6f49838",
  "lastOpenFiles": [
    "LLM/Advantage of ChatPromptTemplate over PromptTemplate on chat models.md",
    "LLM/ConversationSummaryMemory.md",
    "Attachments/Pasted image 20230611152545.png",
    "Attachments/Pasted image 20230611152530.png",
    "Attachments/Pasted image 20230611152500.png",
    "LLM/Memory in Langchain.md",
    "LLM/ConversationTokenBufferMemory.md",
    "Attachments/Pasted image 20230611151545.png",
    "LLM/ConversationBufferWindowMemory.md",
    "Attachments/Pasted image 20230611151318.png",
    "Attachments/Pasted image 20230611151300.png",
    "Attachments/Pasted image 20230611151243.png",
    "Attachments/Pasted image 20230611150816.png",
    "Attachments/Pasted image 20230611150750.png",
    "LLM/ConversationBufferMemory.md",
    "Attachments/Pasted image 20230611150506.png",
    "LLM/Why we need output parser.md",
    "LLM/Prompt Template in Langchain.md",
    "LLM/Advantage of using Langchain.md",
    "basic gradio app.md",
    "LLM/Output Parser.md",
    "LLM/What is output parser.md",
    "LLM/using output parser.md",
    "LLM/test_t.md",
    "test page new.md",
    "LLM/LLM Notes.md",
    "Prompt using OpenAI.md",
    "RainDrop/Webs/20 Best Productivity Podcasts You Have To Listen To in 2023 - Quidlo.md",
    "Untitled 5.md",
    "RainDrop/Webs",
    "RainDrop",
    "Prompt template.md",
    "Untitled 4.md",
    "LLM/Openai Helper Function.md",
    "LLM/Langchain.md",
    "langchain.md",
    "entity roles and groups.md",
    "synonyms.md",
    "test.sh",
    "Templates",
    "LLM/Andrew course",
    "LLM",
    "Excalidraw/ChatChef.excalidraw",
    "ChatChef",
    "Excalidraw",
    "desktop.ini"
  ]
}