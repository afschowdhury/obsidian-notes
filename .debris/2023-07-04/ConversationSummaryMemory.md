---
type: Coding  
tags: llm ,langchain
category: work
for_inteview: True
creation_date: 2023-06-11 15:20
modification_date: 2023-06-11 15:20
---

  
Current Folder : LLM




[[11-06-2023]]


this type of memory takes a llm in its initialization. it summarizes the chats as its name suggests. it has a paramerter `max_token_limit`  . like [[ConversationTokenBufferMemory]] it will keep the tokens specified in max token and summarize the previous.
![[Pasted image 20230611152500.png]]
![[Pasted image 20230611152530.png]]

![[Pasted image 20230611152545.png]]

